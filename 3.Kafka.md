## Kafka ç®€ä»‹

Apache Kafka æ˜¯ä¸€ä¸ª**åˆ†å¸ƒå¼ã€é«˜ååã€å¯æ‰©å±•ã€æŒä¹…åŒ–**çš„æµæ•°æ®å¹³å°ï¼Œæœ€åˆç”± LinkedIn å¼€å‘ï¼Œäº 2011 å¹´å¼€æºï¼Œç°ç”± Apache è½¯ä»¶åŸºé‡‘ä¼šç»´æŠ¤ã€‚å®ƒè¢«å¹¿æ³›ç”¨äºæ„å»ºå®æ—¶æ•°æ®ç®¡é“å’Œæµå¼åº”ç”¨ã€‚

ğŸ“š å®˜ç½‘ï¼šhttps://kafka.apache.org
ğŸ“˜ æ–‡æ¡£ï¼šhttps://kafka.apache.org/documentation/

------

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§                 | è¯´æ˜                                                   |
| -------------------- | ------------------------------------------------------ |
| **é«˜ååé‡**         | å•æœºæ¯ç§’å¯å¤„ç†æ•°åä¸‡æ¡æ¶ˆæ¯ï¼Œæ”¯æŒ TB çº§/å¤©çš„æ•°æ®        |
| **ä½å»¶è¿Ÿ**           | æ¯«ç§’çº§æ¶ˆæ¯ä¼ é€’å»¶è¿Ÿ                                     |
| **æŒä¹…åŒ–å­˜å‚¨**       | æ¶ˆæ¯å†™å…¥ç£ç›˜å¹¶æ”¯æŒå¤šå‰¯æœ¬ï¼Œä¿è¯æ•°æ®ä¸ä¸¢å¤±               |
| **æ°´å¹³æ‰©å±•**         | æ”¯æŒé›†ç¾¤éƒ¨ç½²ï¼Œè½»æ¾æ‰©å±•ååèƒ½åŠ›                         |
| **å®¹é”™æ€§å¼º**         | å‰¯æœ¬æœºåˆ¶ä¿éšœèŠ‚ç‚¹æ•…éšœæ—¶æœåŠ¡ä¸ä¸­æ–­                       |
| **é¡ºåºä¿è¯**         | åœ¨åˆ†åŒºå†…ï¼ˆPartitionï¼‰ä¸¥æ ¼ä¿è¯æ¶ˆæ¯é¡ºåº                  |
| **æ”¯æŒå¤šç§æ¶ˆè´¹æ¨¡å¼** | æ”¯æŒå®æ—¶æµå¤„ç†ï¼ˆStream Processingï¼‰å’Œä¼ ç»Ÿé˜Ÿåˆ—/å‘å¸ƒè®¢é˜… |

------

## ğŸ“¦ æ ¸å¿ƒæ¦‚å¿µ

### 1. **Topicï¼ˆä¸»é¢˜ï¼‰**

- æ¶ˆæ¯çš„é€»è¾‘åˆ†ç±»ï¼Œç±»ä¼¼æ•°æ®åº“ä¸­çš„â€œè¡¨â€
- ç”Ÿäº§è€…å°†æ¶ˆæ¯å‘å¸ƒåˆ° Topicï¼Œæ¶ˆè´¹è€…ä» Topic è®¢é˜…æ¶ˆæ¯
- ä¾‹å¦‚ï¼š`user-activity`, `order-events`

### 2. **Partitionï¼ˆåˆ†åŒºï¼‰**

- æ¯ä¸ª Topic å¯åˆ’åˆ†ä¸ºå¤šä¸ª Partitionï¼Œå®ç°**å¹¶è¡Œå¤„ç†**å’Œ**æ°´å¹³æ‰©å±•**
- æ¯ä¸ª Partition æ˜¯ä¸€ä¸ªæœ‰åºã€ä¸å¯å˜çš„æ¶ˆæ¯åºåˆ—
- æ¶ˆæ¯åœ¨ Partition å†…æŒ‰è¿½åŠ é¡ºåºå†™å…¥ï¼Œå¹¶åˆ†é…å”¯ä¸€åç§»é‡ï¼ˆOffsetï¼‰

### 3. **Producerï¼ˆç”Ÿäº§è€…ï¼‰**

- å‘ Kafka Topic å‘é€æ¶ˆæ¯çš„å®¢æˆ·ç«¯
- å¯æŒ‡å®šåˆ†åŒºç­–ç•¥ï¼ˆå¦‚è½®è¯¢ã€Key Hash ç­‰ï¼‰

### 4. **Consumerï¼ˆæ¶ˆè´¹è€…ï¼‰**

- ä» Kafka Topic è¯»å–æ¶ˆæ¯çš„å®¢æˆ·ç«¯
- ä»¥ **Consumer Groupï¼ˆæ¶ˆè´¹è€…ç»„ï¼‰** å½¢å¼ç»„ç»‡ï¼š
  - åŒä¸€ç»„å†…ï¼šæ¯ä¸ª Partition åªèƒ½è¢«ä¸€ä¸ª Consumer æ¶ˆè´¹ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
  - ä¸åŒç»„é—´ï¼šå¹¿æ’­æ¨¡å¼ï¼Œå„è‡ªç‹¬ç«‹æ¶ˆè´¹å…¨é‡æ•°æ®

### 5. **Brokerï¼ˆä»£ç†ï¼‰**

- Kafka é›†ç¾¤ä¸­çš„å•ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹
- è´Ÿè´£å­˜å‚¨æ•°æ®ã€å¤„ç†è¯»å†™è¯·æ±‚

### 6. **ZooKeeper / KRaftï¼ˆå…ƒæ•°æ®ç®¡ç†ï¼‰**

- **æ—§ç‰ˆæœ¬ï¼ˆ<3.3ï¼‰**ï¼šä¾èµ– ZooKeeper ç®¡ç†é›†ç¾¤å…ƒæ•°æ®ã€Leader é€‰ä¸¾ç­‰
- **æ–°ç‰ˆæœ¬ï¼ˆâ‰¥3.3ï¼‰**ï¼šæ”¯æŒ **KRaft æ¨¡å¼ï¼ˆKafka Raft Metadata modeï¼‰**ï¼Œ**æ— éœ€ ZooKeeper**ï¼Œå®ç°è‡ªç®¡ç†

------

## ğŸ”„ å·¥ä½œæµç¨‹ç¤ºä¾‹

```mermaid
flowchart TD
    P[Producer] -->|å‘é€æ¶ˆæ¯| T[Topic]
    T --> P0[Partition 0]
    T --> P1[Partition 1]
    T --> P2[Partition 2]

    subgraph GroupA[Consumer Group A]
        A1[Consumer A1]
        A2[Consumer A2]
    end

    subgraph GroupB[Consumer Group B]
        B1[Consumer B1]
    end

    P0 --> A1
    P1 --> A2
    P2 --> A2

    P0 --> B1
    P1 --> B1
    P2 --> B1

    style GroupA fill:#e6f3ff,stroke:#333
    style GroupB fill:#f0f9ff,stroke:#333
```

- ç”Ÿäº§è€…å‘é€æ¶ˆæ¯åˆ° `orders` Topic
- Topic åˆ†ä¸º 3 ä¸ª Partition
- Consumer Group A ä¸­æœ‰ 2 ä¸ªæ¶ˆè´¹è€…ï¼šC1 æ¶ˆè´¹ P0+P1ï¼ŒC2 æ¶ˆè´¹ P2
- Consumer Group B ç‹¬ç«‹æ¶ˆè´¹å…¨éƒ¨ Partitionï¼ˆå¹¿æ’­ï¼‰

------

## ğŸ› ï¸ å…¸å‹åº”ç”¨åœºæ™¯

| åœºæ™¯         | è¯´æ˜                                          |
| ------------ | --------------------------------------------- |
| **æ—¥å¿—èšåˆ** | æ”¶é›†åˆ†å¸ƒå¼ç³»ç»Ÿæ—¥å¿—ï¼Œç»Ÿä¸€å¤„ç†åˆ†æ              |
| **æ¶ˆæ¯é˜Ÿåˆ—** | æ›¿ä»£ RabbitMQ/ActiveMQï¼Œè§£è€¦ç³»ç»Ÿ              |
| **æµå¼å¤„ç†** | ä¸ Kafka Streamsã€Flinkã€Spark Streaming é›†æˆ |
| **äº‹ä»¶æº¯æº** | è®°å½•ä¸šåŠ¡äº‹ä»¶ï¼Œæ”¯æŒçŠ¶æ€é‡å»º                    |
| **æŒ‡æ ‡ç›‘æ§** | å®æ—¶é‡‡é›†å’Œåˆ†æç³»ç»ŸæŒ‡æ ‡                        |
| **æ•°æ®é›†æˆ** | ä½¿ç”¨ Kafka Connect åŒæ­¥æ•°æ®åº“ã€æ•°æ®æ¹–ç­‰       |

## âœ… æ€»ç»“

> **Kafka ä¸åªæ˜¯ä¸€ä¸ªæ¶ˆæ¯é˜Ÿåˆ—ï¼Œè€Œæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼çš„å®æ—¶æ•°æ®æµå¹³å°ã€‚**

å®ƒé€šè¿‡**åˆ†åŒºã€å‰¯æœ¬ã€æŒä¹…åŒ–ã€æ¶ˆè´¹è€…ç»„**ç­‰æœºåˆ¶ï¼Œåœ¨**é«˜ååã€å®¹é”™ã€å¯æ‰©å±•**ä¹‹é—´å–å¾—æä½³å¹³è¡¡ï¼Œå·²æˆä¸ºç°ä»£æ•°æ®æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ã€‚

é€‚ç”¨äºï¼š

- éœ€è¦å¤„ç†æµ·é‡å®æ—¶æ•°æ®çš„åœºæ™¯
- è¦æ±‚æ¶ˆæ¯å¯é‡æ”¾ã€å®¡è®¡ã€å›æº¯çš„ç³»ç»Ÿ
- æ„å»ºäº‹ä»¶é©±åŠ¨å¾®æœåŠ¡æ¶æ„ï¼ˆEvent-Driven Architectureï¼‰



## ğŸ¥‡é›†æˆç¤ºä¾‹

âœ¨ä»£ç æ–‡ä»¶ [middleware-message/kafka at master Â· xiaopengooo0/middleware-message](https://github.com/xiaopengooo0/middleware-message/tree/master/kafka)

### 1.ä¾èµ–å¼•å…¥

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

### 2.é…ç½®æ–‡ä»¶

```yml
spring:
  kafka:
    listener:
      # RECORD: æ¯å¤„ç†ä¸€æ¡è®°å½•åç«‹å³æäº¤åç§»é‡
      # BATCH: å¤„ç†å®Œä¸Šä¸€æ‰¹æ¬¡çš„æ‰€æœ‰è®°å½•åæäº¤åç§»é‡
      # TIME: è¾¾åˆ°è®¾å®šçš„ackTimeæ—¶é—´åæäº¤åç§»é‡
      # COUNT: å¤„ç†è®°å½•æ•°é‡è¾¾åˆ°ackCountåæäº¤åç§»é‡
      # COUNT_TIME: æ•°é‡æˆ–æ—¶é—´ä»»ä¸€æ¡ä»¶æ»¡è¶³æ—¶æäº¤åç§»é‡
      # MANUAL: éœ€è¦æ‰‹åŠ¨ç¡®è®¤ï¼Œæ‰€æœ‰è®°å½•å¤„ç†å®Œæˆåæäº¤åç§»é‡
      # MANUAL_IMMEDIATE: æ‰‹åŠ¨ç¡®è®¤ï¼Œå¦‚æœåœ¨æ¶ˆè´¹è€…çº¿ç¨‹ä¸­ç¡®è®¤åˆ™ç«‹å³æäº¤
      ack-mode: manual
#      type: batch # æ‰¹é‡å¤„ç†ï¼Œé»˜è®¤æ˜¯å•æ¡
    bootstrap-servers: localhost:9092 # kafka server
    producer: #  åºåˆ—åŒ–
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all # ç¡®ä¿æ¶ˆæ¯è¢«å†™å…¥
    consumer:
      group-id: kafka-consumer-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest  # è‡ªåŠ¨åç§»é‡
      enable-auto-commit: false  # è‡ªåŠ¨æäº¤
      # è®¾ç½®æ‰¹é‡å¤„ç†ç›¸å…³é…ç½®
      #max-poll-records: 3  # æ¯æ¬¡æ‹‰å–æœ€å¤š10æ¡è®°å½•
```

> [!NOTE]
>
> `listener.type = batch ` å’Œ `max-poll-records = 3` æ˜¯æ‰¹é‡å¤„ç†ï¼Œé»˜è®¤æ˜¯å•æ¡å¤„ç†ã€‚å¯¹åº”ä¸‹æ–¹æ¶ˆè´¹è€…`consumeBatch`å¯ä»¥æ‰¹é‡å¤„ç†æ¶ˆæ¯ã€‚

### 3. é…ç½®æ³¨å…¥

```java
@Configuration
@EnableKafka
public class KafkaConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;


    @Bean
    public ProducerFactory<String, String> producerFactory() {
        HashMap<String, Object> prop = new HashMap<>();
        prop.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        prop.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        prop.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(prop);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }



}
```

### 4.ç”Ÿäº§è€…é…ç½®

```java
@Component
public class KafkaProducer {


    private static final Logger log = LoggerFactory.getLogger(KafkaProducer.class);
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;


    private static final String TOPIC = "kafka";



    public void sendMessage(String key, String message) {
        log.info("ã€KafkaProducerã€‘å‘é€æ¶ˆæ¯ï¼š{}", message);
        // å‘é€æ¶ˆæ¯
        ListenableFuture<SendResult<String, String>> future = kafkaTemplate.send(TOPIC, key, message);
        future.addCallback(new ListenableFutureCallback<SendResult<String, String>>() {
            @Override
            public void onFailure(Throwable ex) {
                log.error("ã€KafkaProducerã€‘å‘é€æ¶ˆæ¯å¤±è´¥ï¼š{}", ex.getMessage());
            }

            @Override
            public void onSuccess(SendResult<String, String> result) {
                log.info("ã€KafkaProducerã€‘å‘é€æ¶ˆæ¯æˆåŠŸï¼š{}", result.toString());
            }
        });
    }

    /**
     * å‘é€å¤šæ¡æ¶ˆæ¯
     * @param key
     * @param message
     */
    @Transactional
    public void sendMessageTransaction(String key, String message) {
        log.info("ã€KafkaProducerã€‘å‘é€äº‹åŠ¡æ¶ˆæ¯ï¼š{}", message);
        kafkaTemplate.executeInTransaction(operations -> {
            operations.send(TOPIC, key, message);
            return true;
        });
    }
}
```

### 5.æ¶ˆè´¹è€…é…ç½®

```java
@Component
public class KafkaConsumer {

    private static final Logger log = LoggerFactory.getLogger(KafkaConsumer.class);

    /**
     * ä½¿ç”¨@Headeræ³¨è§£ä»Kafkaæ¶ˆæ¯å¤´ä¸­æå–ç‰¹å®šä¿¡
     * @param message
     * @param ack
     * @param key
     */
    // å•æ¡æ¶ˆæ¯æ¶ˆè´¹
    @KafkaListener(topics = "kafka", groupId = "kafka-consumer-group")
    public void consumer(String message,
                         Acknowledgment ack,
                         @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY) String key
    ) {
        try {
            log.info("Received message - Key: {}, Value: {}", key, message);

            //å¤„ç†ä¸šåŠ¡é€»è¾‘
            log.info("ã€KafkaConsumerã€‘å¤„ç†ä¸šåŠ¡é€»è¾‘....");
            // ç¡®è®¤æ¶ˆè´¹
            ack.acknowledge();
        } catch (Exception e) {
            log.error("ã€KafkaConsumerã€‘å¤„ç†ä¸šåŠ¡é€»è¾‘å¤±è´¥ï¼š{}", e.getMessage());
        }
    }


    // æ‰¹é‡æ¶ˆè´¹ - å¯ç”¨è¿™ä¸ªç›‘å¬å™¨æ¥æµ‹è¯•æ‰¹é‡å¤„ç†
    @KafkaListener(topics = "kafka", groupId = "kafka-consumer-batch-group")
    public void consumeBatch(List<String> messages, Acknowledgment ack) {
        log.info("=== æ‰¹é‡æ¶ˆè´¹å¼€å§‹ ===");
        log.info("Received batch of {} messages", messages.size());
        for (String message : messages) {
            log.info("Batch processing message: {}", message);
        }
        log.info("=== æ‰¹é‡æ¶ˆè´¹ç»“æŸ ===");
        ack.acknowledge();
    }
}
```

### 6. æµ‹è¯•æ¶ˆæ¯

```java
@SpringBootTest
@RunWith(SpringRunner.class)
public class ApiTest {


    @Resource
    private KafkaProducer kafkaProducer;



    @Test
    public void sendMessage() throws InterruptedException {
        // å¿«é€Ÿè¿ç»­å‘é€å¤šæ¡æ¶ˆæ¯
        for (int i = 1; i <= 5; i++) {
            kafkaProducer.sendMessage(String.valueOf(i), "hello kafka " + i);
        }
        // ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿æ¶ˆè´¹è€…å¤„ç†å®Œæ¶ˆæ¯
        Thread.sleep(1000);
    }
}
```

### è¾“å‡ºç¤ºä¾‹

#### é»˜è®¤å¤„ç†ï¼ˆå•æ¡ï¼‰



```powershell
2025-10-31 10:31:19.750  INFO 39504 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : kafka-consumer-group: partitions assigned: [kafka-0]
2025-10-31 10:31:19.768  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Received message - Key: 1, Value: hello kafka 1
2025-10-31 10:31:19.768  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : ã€KafkaConsumerã€‘å¤„ç†ä¸šåŠ¡é€»è¾‘....
2025-10-31 10:31:19.774  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Received message - Key: 2, Value: hello kafka 2
2025-10-31 10:31:19.774  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : ã€KafkaConsumerã€‘å¤„ç†ä¸šåŠ¡é€»è¾‘....
2025-10-31 10:31:19.776  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Received message - Key: 3, Value: hello kafka 3
2025-10-31 10:31:19.776  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : ã€KafkaConsumerã€‘å¤„ç†ä¸šåŠ¡é€»è¾‘....
2025-10-31 10:31:19.778  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Received message - Key: 4, Value: hello kafka 4
2025-10-31 10:31:19.779  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : ã€KafkaConsumerã€‘å¤„ç†ä¸šåŠ¡é€»è¾‘....
2025-10-31 10:31:19.782  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Received message - Key: 5, Value: hello kafka 5
2025-10-31 10:31:19.782  INFO 39504 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : ã€KafkaConsumerã€‘å¤„ç†ä¸šåŠ¡é€»è¾‘....
```

#### æ‰¹é‡å¤„ç†

> [!NOTE]
>
> ä¿®æ”¹é…ç½® `ack-mode: manual`,`type:batch`,`max-poll-records: 3`

```powershell
2025-10-31 10:42:54.253  INFO 21752 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : kafka-consumer-batch-group: partitions assigned: [kafka-0]
2025-10-31 10:42:54.272  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : === æ‰¹é‡æ¶ˆè´¹å¼€å§‹ ===
2025-10-31 10:42:54.272  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Received batch of 3 messages
2025-10-31 10:42:54.272  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Batch processing message: hello kafka 1
2025-10-31 10:42:54.272  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Batch processing message: hello kafka 2
2025-10-31 10:42:54.272  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Batch processing message: hello kafka 3
2025-10-31 10:42:54.272  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : === æ‰¹é‡æ¶ˆè´¹ç»“æŸ ===
2025-10-31 10:42:54.279  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : === æ‰¹é‡æ¶ˆè´¹å¼€å§‹ ===
2025-10-31 10:42:54.279  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Received batch of 2 messages
2025-10-31 10:42:54.279  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Batch processing message: hello kafka 4
2025-10-31 10:42:54.279  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : Batch processing message: hello kafka 5
2025-10-31 10:42:54.279  INFO 21752 --- [ntainer#0-0-C-1] c.s.m.kafka.consumer.KafkaConsumer       : === æ‰¹é‡æ¶ˆè´¹ç»“æŸ ===
```

### docker é…ç½®

`docker-compose.yml`

```yml
services:
  # RabbitMQ
  kafka:
    image: apache/kafka:3.9.0
    ports:
      - "9092:9092"
```

é•œåƒåœ°å€ï¼š`swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/apache/kafka:3.9.0`

